{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID2214 Assignment 3 Group no. [enter]\n",
    "### Project members: \n",
    "[Enter Name, email]\n",
    "[Enter Name, email]\n",
    "[Enter Name, email]\n",
    "[Enter Name, email]\n",
    "\n",
    "### Declaration\n",
    "By submitting this solution, it is hereby declared that all individuals listed above have contributed to the solution, either with code that appear in the final solution below, or with code that has been evaluated and compared to the final solution, but for some reason has been excluded. It is also declared that all project members fully understand all parts of the final solution and can explain it upon request.\n",
    "\n",
    "It is furthermore declared that the code below is a contribution by the project members only, and specifically that no part of the solution has been copied from any other source (except for lecture slides at the course ID2214) and no part of the solution has been provided by someone not listed as project member above.\n",
    "\n",
    "It is furthermore declared that it has been understood that no other library/package than the Python 3 standard library, NumPy, pandas and time may be used in the solution for this assignment.\n",
    "\n",
    "### Instructions\n",
    "All assignments starting with number 1 below are mandatory. Satisfactory solutions\n",
    "will give 1 point (in total). If they in addition are good (all parts work more or less \n",
    "as they should), completed on time (submitted before the deadline in Canvas) and according\n",
    "to the instructions, together with satisfactory solutions of assignments starting with \n",
    "number 2 below, then the assignment will receive 2 points (in total).\n",
    "\n",
    "It is highly recommended that you do not develop the code directly within the notebook\n",
    "but that you copy the comments and test cases to your regular development environment\n",
    "and only when everything works as expected, that you paste your functions into this\n",
    "notebook, do a final testing (all cells should succeed) and submit the whole notebook \n",
    "(a single file) in Canvas (do not forget to fill in your group number and names above).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NumPy, pandas and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reused functions from Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and paste functions from Assignment 1 here that you need for this assignment\n",
    "\n",
    "def create_normalization(df_init, normalizationtype = 'minmax'):\n",
    "    df = df_init.copy()\n",
    "    normalization = {}\n",
    "    for col in df.columns:\n",
    "        if(col not in ['ID', 'CLASS'] and df[col].dtype in ['float64', 'float32', 'int']):\n",
    "            if(normalizationtype == 'minmax'):\n",
    "                min = df[col].min()\n",
    "                max = df[col].max()\n",
    "                diff = max-min\n",
    "                df[col] = df[col].apply(lambda x: (x-min)/(diff))\n",
    "                normalization[col] = ('minmax', min, max)\n",
    "                \n",
    "            elif(normalizationtype == 'zscore'):\n",
    "                mean = df[col].mean()\n",
    "                std = df[col].std()\n",
    "                df[col] = df[col].apply(lambda x: (x-mean)/(std))\n",
    "                normalization[col] = ('zscore', mean, std)\n",
    "              \n",
    "    return(df, normalization)\n",
    "\n",
    "def apply_normalization(df_init, normalization):\n",
    "    df = df_init.copy()\n",
    "    for col in df.columns:\n",
    "        if(col not in ['ID', 'CLASS'] and df[col].dtype in ['float64', 'float32', 'int']):\n",
    "            normalizationtype, arg1, arg2 = normalization[col]\n",
    "            \n",
    "            if(normalizationtype == 'minmax'):\n",
    "                diff = arg2-arg1\n",
    "                #min(max()) to limit the output range to [0,1], see hint 2\n",
    "                df[col] = df[col].apply(lambda x: min(max((x-arg1)/(diff), 0),1))\n",
    "                \n",
    "            elif(normalizationtype == 'zscore'):\n",
    "                df[col] = df[col].apply(lambda x: (x-arg1)/(arg2))\n",
    "              \n",
    "    return(df)\n",
    "\n",
    "def create_imputation(df_init):\n",
    "    df = df_init.copy()\n",
    "    imputation = {}\n",
    "    nrow = df.shape[0]\n",
    "    for col in df.columns:\n",
    "        type_col = df[col].dtype\n",
    "        \n",
    "        #if colonne to impute as number\n",
    "        if(col not in ['ID', 'CLASS'] and type_col in ['float64', 'float32', 'int64', 'int32']):\n",
    "            na = np.sum(df[col].isna())\n",
    "            if(na == nrow):\n",
    "                mean = 0\n",
    "            else:\n",
    "                mean = df[col].mean()\n",
    "            df[col].fillna(mean, inplace=True)\n",
    "            imputation[col] = mean\n",
    "            \n",
    "        #if column not to impute as object or category\n",
    "        elif(col not in [\"ID\",\"CLASS\"]):                        \n",
    "            na = np.sum(df[col].isna())\n",
    "            if(na == nrow):\n",
    "                if(type_col == 'object'):\n",
    "                    mode = ''\n",
    "                elif(type_col == 'category'):\n",
    "                    mode = df[col].cat.categories[0]\n",
    "            else:\n",
    "                mode = df[col].mode()[0]\n",
    "            df[col].fillna(mode, inplace=True)\n",
    "            imputation[col] = mode\n",
    "            \n",
    "    return(df, imputation)\n",
    "\n",
    "def apply_imputation(df_init, imputation):\n",
    "    df = df_init.copy()\n",
    "    for col in df.columns:\n",
    "        if(col not in ['ID','CLASS']):                                      \n",
    "            df[col].fillna(imputation[col], inplace=True)            \n",
    "    return(df)\n",
    "\n",
    "def create_bins(df_init, nobins = 10, bintype = 'equal-width'):\n",
    "    df = df_init.copy()\n",
    "    binning = {}\n",
    "    for col in df.columns:\n",
    "        type_col = df[col].dtype\n",
    "        \n",
    "        if(col not in ['ID', 'CLASS'] and type_col in ['float64', 'float32', 'int64', 'int32']):\n",
    "            if(bintype == 'equal-width'):\n",
    "                df[col], bins = pd.cut(df[col],nobins,retbins=True, labels = False)\n",
    "            else:\n",
    "                # duplicate = 'drop' in case there are duplicates in the edges\n",
    "                df[col], bins = pd.qcut(df[col],nobins,retbins=True, labels = False, duplicates='drop')\n",
    "            bins[0], bins[-1] = -np.inf, np.inf\n",
    "            binning[col] = bins\n",
    "            df[col] = df[col].astype('category')\n",
    "            df[col] = df[col].cat.set_categories([str(i) for i in df[col].cat.categories], rename = True)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    return(df, binning)\n",
    "\n",
    "def apply_bins(df_init, binning):\n",
    "    df = df_init.copy()\n",
    "    for col in df.columns:\n",
    "        type_col = df[col].dtype\n",
    "        \n",
    "        if(col not in ['ID', 'CLASS'] and type_col in ['float64', 'float32', 'int64', 'int32']):\n",
    "            bins = binning[col]\n",
    "            df[col] = pd.cut(df[col],bins,labels=False)\n",
    "            df[col] = df[col].astype('category')\n",
    "            df[col] = df[col].cat.set_categories([str(i) for i in df[col].cat.categories], rename = True) \n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    return(df)\n",
    "\n",
    "def split(df_init, testfraction = 0.5):\n",
    "    n = df_init.shape[0]\n",
    "    n_test = int(n * testfraction)\n",
    "    indexes = [i for i in range(n)]\n",
    "    np.random.shuffle(indexes)\n",
    "    test_idx = indexes[:n_test]\n",
    "    training_idx = indexes[n_test:]\n",
    "    return(df_init.iloc[training_idx], df_init.iloc[test_idx])\n",
    "\n",
    "def accuracy(predictions, correctlabels):\n",
    "    correct = 0\n",
    "    n = predictions.shape[0]\n",
    "    for i in range(n):\n",
    "        d = predictions.iloc[i]\n",
    "        pred  = d.idxmax()\n",
    "        if(pred == correctlabels[i]):\n",
    "            correct += 1\n",
    "    return(correct/n)\n",
    "\n",
    "def create_one_hot(df_init):\n",
    "    df = df_init.copy()\n",
    "    df2 = df.copy()\n",
    "    one_hot = {}\n",
    "    for col in df.columns:\n",
    "        if((hasattr(df[col], 'object') or hasattr(df[col], 'category')) and col not in ['ID','CLASS']): \n",
    "            df[col] = df[col].astype('category')\n",
    "            n_cat = len(df[col].cat.categories)\n",
    "            one_hot[col] = df[col].cat.categories\n",
    "            for i in one_hot[col]:\n",
    "                name = col+'_'+i   \n",
    "                new_col = df[col]==i\n",
    "                new_col = new_col.astype('float')\n",
    "                df2[name]=new_col \n",
    "            df2 = df2.drop(columns = col, axis = 1) \n",
    "    return(df2, one_hot)\n",
    "\n",
    "def apply_one_hot(df_init, one_hot):\n",
    "    df = df_init.copy()\n",
    "    df2 = df.copy()\n",
    "    for col in df.columns:\n",
    "        if(col in one_hot.keys()):\n",
    "            for i in one_hot[col]:\n",
    "                name = col+'-'+i\n",
    "                new_col = df[col]==i\n",
    "                new_col = pd.Series(new_col.astype('float'))\n",
    "                df2[name] = new_col\n",
    "            df2 = df2.drop(columns = col, axis = 1)\n",
    "            \n",
    "    return(df2)\n",
    "\n",
    "def folds(df, nofolds):\n",
    "    shuffling = np.random.permutation(df.index)\n",
    "    intervals = [int(i*df.shape[0]/nofolds) for i in range(nofolds+1)]\n",
    "    listDf = [df.iloc[intervals[i]:intervals[i+1],:] for i in range(nofolds)]\n",
    "    return(listDf)\n",
    "\n",
    "def brier_score(df, correctlabels):\n",
    "    n = df.shape[0]\n",
    "    avg_error = 0\n",
    "    for i in range(n):\n",
    "        v = np.array(df.iloc[i,:])\n",
    "        idx = np.where(df.columns==correctlabels[i])[0]\n",
    "        correct = [1 if i == idx else 0 for i in range(df.shape[1])]\n",
    "        error = np.sum((v-correct)**2)\n",
    "        avg_error += error\n",
    "    avg_error = avg_error / n\n",
    "    return(avg_error)\n",
    "\n",
    "def get_true_false_positive(prediction_vector, label_vector, label):\n",
    "    pred = np.array(prediction_vector)\n",
    "    v = [i == label for i in label_vector] \n",
    "    this_label, not_this_label = pred[v], pred[[not i for i in v]]\n",
    "    return(this_label, not_this_label)\n",
    "\n",
    "def get_list(prediction_vector, label_vector, label):\n",
    "    this_label, not_this_label = get_true_false_positive(prediction_vector, label_vector, label)\n",
    "    scores_false = [0]\n",
    "    scores_false += sorted(prediction_vector)\n",
    "    scores_false += [1]\n",
    "    dict_scores = {}\n",
    "    for i in scores_false:\n",
    "        if(len(not_this_label)==0):\n",
    "            false_pos_i_r = 0\n",
    "        else:\n",
    "            false_pos_i_r = np.sum(not_this_label>=i)/len(not_this_label)\n",
    "        if(len(this_label)==0):\n",
    "            true_pos_i_r = 0\n",
    "        else:\n",
    "            true_pos_i_r = np.sum(this_label>=i)/len(this_label)\n",
    "        dict_scores[i] = [false_pos_i_r, true_pos_i_r]\n",
    "    list_reversed = [i for i in reversed(list(dict_scores.values()))]\n",
    "    return(list_reversed)\n",
    "\n",
    "def get_area(list_values):\n",
    "    area = 0\n",
    "    if([0,0] not in list_values):\n",
    "        list_values = [[0,0]]+list_values\n",
    "    if([1,1] not in list_values):\n",
    "        list_values = list_values+[[1,1]]\n",
    "    n = len(list_values)\n",
    "    for i in range(n-1):\n",
    "        left, right = i, i+1\n",
    "        tpr_left, tpr_right = list_values[left][1], list_values[right][1]\n",
    "        fpr_left, fpr_right = list_values[left][0], list_values[right][0]\n",
    "        if(fpr_right==fpr_left):\n",
    "            next\n",
    "        height = (tpr_left+tpr_right)/2\n",
    "        width = fpr_right-fpr_left\n",
    "        area += height*width\n",
    "    return(area)\n",
    "\n",
    "def get_frequencies(correctlabels, nClasses):\n",
    "    x = pd.Series(correctlabels)\n",
    "    frequencies = x.value_counts(normalize = True)\n",
    "    d_freq = dict(frequencies)\n",
    "    freqs = []\n",
    "    for i in range(1,nClasses+1):\n",
    "        if(i not in d_freq):\n",
    "            d_freq[i] = 0\n",
    "    return(d_freq)\n",
    "    \n",
    "def auc(df, correctlabels):\n",
    "    nClasses = df.shape[1]\n",
    "    frequencies = get_frequencies(correctlabels, nClasses)\n",
    "\n",
    "    area = 0\n",
    "    for col in df.columns:\n",
    "        prediction_vector = df[col]\n",
    "        l = get_list(prediction_vector, correctlabels, col)\n",
    "        area_col = get_area(l)\n",
    "        area += frequencies[col]*area_col\n",
    "    return(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the class DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.binning = None\n",
    "        self.imputation = None\n",
    "        self.labels = None\n",
    "        self.model = None\n",
    "        # nodenomax is the maximum nodeno which has been given to a tree so it is a reference to know what should\n",
    "        # be the nodeno of the next node\n",
    "        self.nodenomax = 0\n",
    "        \n",
    "    ## This function takes a list of feature and a dataframe and gives the feature_to_select: the feature which minimises \n",
    "    ## the residual information and the list of sub_features which is the features minus the feature_to_select\n",
    "    def select_feature_min_inf(self,features, df):\n",
    "        # spec_agg is a special aggregation function\n",
    "        # the input df is a groupedby dataframe, which is a groupedby df by featureI (one feature selected) of a dataframe\n",
    "        # which is itself a size() dataframe by (featureI, class)\n",
    "        # This aim of this function is to give the residual information for one feature\n",
    "        # NB: We do not divide by the total cardinal as it would be the same for all features.\n",
    "        def spec_agg(df):\n",
    "            return(-np.sum(df*np.log(df/np.sum(df))))\n",
    "    \n",
    "        idx, minInf = 0, 1e5\n",
    "        for i in range(len(features)):\n",
    "            f = features[i]\n",
    "            # observed = True allows to remove the NA version of counts for categorical data, sort False for speed\n",
    "            class_repart = df.groupby([f, 'CLASS'], observed=True, sort = False).size()\n",
    "            # By aggregating with spec_agg we compute the inf residual in an efficient way\n",
    "            inf = class_repart.groupby([f], sort = False).agg(spec_agg).sum()\n",
    "            if(inf < minInf):\n",
    "                minInf = inf\n",
    "                idx = i\n",
    "        feature_to_select = features[idx]\n",
    "        sub_features = features[:idx] + features[idx+1:]\n",
    "        return(feature_to_select, sub_features)\n",
    "    \n",
    "    \n",
    "    def divide_and_conquer(self, df, features, class_freq, min_samples_split, nodeno):\n",
    "        feature_to_select, sub_features = self.select_feature_min_inf(features,df)\n",
    "        #Generating the sub trees\n",
    "        values = df[feature_to_select].unique()\n",
    "        trees = []\n",
    "        sub_nodeno = self.nodenomax\n",
    "        nodedict = {}\n",
    "        # Made to improve the speed\n",
    "        df.set_index(feature_to_select, inplace=True)\n",
    "        for i in values:\n",
    "            sub_df = df.loc[[i]]\n",
    "            sub_class_freq = sub_df.CLASS.value_counts(normalize=True)\n",
    "            self.nodenomax += 1\n",
    "            nodedict[i] = self.nodenomax\n",
    "            # We are checking if we should create a new sub tree or if we should create a leaf\n",
    "            # leaf if we have less instances than min_sample or if we don't have anymore features\n",
    "            if((sub_df.shape[0]<=min_samples_split or len(sub_features)==0)):\n",
    "                sub_tree = ((self.nodenomax, \"leaf\", sub_class_freq))\n",
    "            else:\n",
    "                sub_tree = self.divide_and_conquer(sub_df, sub_features, sub_class_freq, min_samples_split, self.nodenomax)\n",
    "                \n",
    "            self.model.append(sub_tree)\n",
    "        this_tree = (nodeno, feature_to_select, nodedict)\n",
    "        return(this_tree)\n",
    "    \n",
    "    def fit(self, df, nobins=10, bintype='equal-width', min_samples_split = 5):\n",
    "        self.__init__()\n",
    "        self.model = []\n",
    "        df, self.imputation = create_imputation(df)\n",
    "        classColumn = df.loc[:,'CLASS'].astype('category')\n",
    "        self.labels = classColumn.cat.categories\n",
    "        df, self.binning = create_bins(df, nobins = nobins, bintype = bintype)\n",
    "        features = df.columns\n",
    "        features = list(features.drop(['CLASS', 'ID']))\n",
    "        class_freq = df.CLASS.value_counts(normalize=True).sort_index()\n",
    "        root_node = self.divide_and_conquer(df, features, class_freq, min_samples_split, 0)\n",
    "        self.model.append(root_node)\n",
    "        # We sort given the nodeno\n",
    "        self.model = sorted(self.model, key=lambda x:x[0])\n",
    "        \n",
    "    ## This recursive funtion takes a row and a nodeno and will go through the nodes to find the probabilities\n",
    "    ## giving back a vector of size number of labels\n",
    "    def make_prediction(self, nodeno, row):\n",
    "        nodeno, f, d = self.model[nodeno]\n",
    "        if(f == \"leaf\"):\n",
    "            return(d.sort_index())\n",
    "        else:\n",
    "            value = row[f]\n",
    "            # We have some case where we don't have any node for the values of row\n",
    "            if(value not in d.keys()):\n",
    "                # if so we will go in the deepest node compatible and average the predictions of the sub_nodes\n",
    "                v = list(d.values())\n",
    "                m = np.zeros([len(v), len(self.labels)])\n",
    "                for i in range(len(v)):\n",
    "                     m[i] = self.make_prediction(v[i], row)\n",
    "                m = np.mean(m, axis = 0)\n",
    "                return(m)\n",
    "            # else we just iterate in the good next node\n",
    "            else:\n",
    "                new_nodeno = d[value]\n",
    "            return(self.make_prediction(new_nodeno, row))\n",
    "        \n",
    "    def predict(self, df):\n",
    "        df = df.drop(['ID', 'CLASS'], axis = 1)\n",
    "        df = apply_imputation(df_init=df, imputation=self.imputation)\n",
    "        df = apply_bins(df_init=df, binning=self.binning)\n",
    "        matrix = np.array([np.zeros(len(self.labels)) for i in range (df.shape[0])])\n",
    "        for i in range(df.shape[0]):\n",
    "            row = df.iloc[i]\n",
    "            matrix[i] = self.make_prediction(0, row)\n",
    "        probs = pd.DataFrame(matrix, columns=self.labels)\n",
    "        # We need to add the predictions of the labels that might not have been present in the training set\n",
    "        # for example label 4 is never represented so it should appear wth a prob of 0 for all rows\n",
    "        max_i = np.max(a=np.array(probs.columns, dtype='int'))\n",
    "        for i in range(1,max_i):\n",
    "            if (i not in probs.columns):\n",
    "                probs[i] = 0\n",
    "        cols = sorted(predictions.columns)\n",
    "        probs = probs.loc[:,cols]\n",
    "        return(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (5, 'equal-width', 3): 3.60 s.\n",
      "Testing time (5, 'equal-width', 3): 0.26 s.\n",
      "Training time (5, 'equal-width', 5): 1.84 s.\n",
      "Testing time (5, 'equal-width', 5): 0.33 s.\n",
      "Training time (5, 'equal-width', 10): 0.91 s.\n",
      "Testing time (5, 'equal-width', 10): 0.52 s.\n",
      "Training time (5, 'equal-size', 3): 2.97 s.\n",
      "Testing time (5, 'equal-size', 3): 0.16 s.\n",
      "Training time (5, 'equal-size', 5): 2.94 s.\n",
      "Testing time (5, 'equal-size', 5): 0.63 s.\n",
      "Training time (5, 'equal-size', 10): 2.02 s.\n",
      "Testing time (5, 'equal-size', 10): 0.26 s.\n",
      "Training time (10, 'equal-width', 3): 2.49 s.\n",
      "Testing time (10, 'equal-width', 3): 0.33 s.\n",
      "Training time (10, 'equal-width', 5): 2.19 s.\n",
      "Testing time (10, 'equal-width', 5): 0.28 s.\n",
      "Training time (10, 'equal-width', 10): 0.95 s.\n",
      "Testing time (10, 'equal-width', 10): 0.14 s.\n",
      "Training time (10, 'equal-size', 3): 1.85 s.\n",
      "Testing time (10, 'equal-size', 3): 0.23 s.\n",
      "Training time (10, 'equal-size', 5): 1.45 s.\n",
      "Testing time (10, 'equal-size', 5): 0.21 s.\n",
      "Training time (10, 'equal-size', 10): 1.12 s.\n",
      "Testing time (10, 'equal-size', 10): 0.19 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-width</th>\n",
       "      <th>3</th>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.569085</td>\n",
       "      <td>0.787104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.573103</td>\n",
       "      <td>0.789411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.565079</td>\n",
       "      <td>0.791692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-size</th>\n",
       "      <th>3</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.689916</td>\n",
       "      <td>0.749279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.630872</td>\n",
       "      <td>0.762795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.652672</td>\n",
       "      <td>0.743455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-width</th>\n",
       "      <th>3</th>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.535986</td>\n",
       "      <td>0.833842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.544863</td>\n",
       "      <td>0.824130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.588785</td>\n",
       "      <td>0.509364</td>\n",
       "      <td>0.839930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-size</th>\n",
       "      <th>3</th>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.907885</td>\n",
       "      <td>0.653384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.907745</td>\n",
       "      <td>0.652530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.823100</td>\n",
       "      <td>0.649869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy  Brier score       AUC\n",
       "5  equal-width 3   0.635514     0.569085  0.787104\n",
       "               5   0.607477     0.573103  0.789411\n",
       "               10  0.570093     0.565079  0.791692\n",
       "   equal-size  3   0.598131     0.689916  0.749279\n",
       "               5   0.635514     0.630872  0.762795\n",
       "               10  0.598131     0.652672  0.743455\n",
       "10 equal-width 3   0.654206     0.535986  0.833842\n",
       "               5   0.598131     0.544863  0.824130\n",
       "               10  0.588785     0.509364  0.839930\n",
       "   equal-size  3   0.485981     0.907885  0.653384\n",
       "               5   0.485981     0.907745  0.652530\n",
       "               10  0.504673     0.823100  0.649869"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code (leave this part unchanged, except for if auc is undefined)\n",
    "\n",
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.txt\")\n",
    "\n",
    "tree_model = DecisionTree()\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "nobins_values = [5,10]\n",
    "bintype_values = [\"equal-width\",\"equal-size\"]\n",
    "min_samples_split_values = [3,5,10]\n",
    "parameters = [(nobins,bintype,min_samples_split) for nobins in nobins_values for bintype in bintype_values \n",
    "              for min_samples_split in min_samples_split_values]\n",
    "\n",
    "results = np.empty((len(parameters),3))\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    t0 = time.perf_counter()\n",
    "    tree_model.fit(glass_train_df,nobins=parameters[i][0],bintype=parameters[i][1],min_samples_split=parameters[i][2])\n",
    "    print(\"Training time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = tree_model.predict(glass_test_df)\n",
    "    print(\"Testing time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels),\n",
    "                  auc(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=pd.MultiIndex.from_product([nobins_values,bintype_values,min_samples_split_values]),\n",
    "                       columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.97\n",
      "AUC on training set: 1.00\n",
      "Brier score on training set: 0.03\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTree()\n",
    "train_labels = glass_train_df[\"CLASS\"]\n",
    "tree_model.fit(glass_train_df,min_samples_split=1)\n",
    "predictions = tree_model.predict(glass_train_df)\n",
    "print(\"Accuracy on training set: {0:.2f}\".format(accuracy(predictions,train_labels)))\n",
    "print(\"AUC on training set: {0:.2f}\".format(auc(predictions,train_labels)))\n",
    "print(\"Brier score on training set: {0:.2f}\".format(brier_score(predictions,train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class DecisionTree with three functions __init__, fit and predict (after the comments):\n",
    "#\n",
    "# Input to __init__: \n",
    "# self: the object itself\n",
    "#\n",
    "# Output from __init__:\n",
    "# nothing\n",
    "# \n",
    "# This function does not return anything but just initializes the following attributes of the object (self) to None:\n",
    "# binning, imputatiom, labels, model\n",
    "#\n",
    "# Input to fit:\n",
    "# self: the object itself\n",
    "# df: a dataframe (where the column names \"CLASS\" and \"ID\" have special meaning)\n",
    "# nobins: no. of bins (default = 10)\n",
    "# bintype: either \"equal-width\" (default) or \"equal-size\"\n",
    "# min_samples_split: no. of instances required to allow a split (default = 5)\n",
    "#\n",
    "# Output from fit:\n",
    "# nothing\n",
    "#\n",
    "# The result of applying this function should be:\n",
    "#\n",
    "# self.binning should be a discretization mapping (see Assignment 1) from df\n",
    "# self.imputation should be an imputation mapping (see Assignment 1) from df\n",
    "# self.labels should be the categories of the \"CLASS\" column of df, set to be of type \"category\" \n",
    "# self.model should be a decision tree (for details, see lecture slides), where the leafs return class probabilities\n",
    "# Note that the function does not return anything but just assigns values to the attributes of the object.\n",
    "#\n",
    "# Hint 1: First find the available features (excluding \"CLASS\" and \"ID\"), then find the class counts, e.g., using \n",
    "#         groupby, and calculate the default class probabilities (relative frequencies of the class labels)\n",
    "# Hint 2: Define a function, e.g., called divide_and_conquer, that takes the above as input together with df \n",
    "#         and min_samples_split, and also a nodeno (starting with 0) to keep track of the generated nodes in the tree\n",
    "# Hint 3: You may represent the tree under construction as a list of nodes (tuples), on the form:\n",
    "#         (nodeno,\"leaf\",class_probabilities): corresponding to a leaf node where class_probabilities is a vector\n",
    "#                                              with the relative class frequencies (ordered according to self.labels)\n",
    "#         (nodeno,feature,node_dict): corresponding to an internal (non-leaf) node where node_dict is a mapping from\n",
    "#                                     the possible values of feature to child nodes (their nodenos)\n",
    "# Hint 4: You may evaluate each feature by a function information_content, which takes the group sizes\n",
    "#         for each possible value of the feature together with the class counts of each group as input\n",
    "# Hint 5: The best feature found (with lowest resulting information content) will be used to split the training\n",
    "#         instances, and each sub-group is used for generating a sub-tree (recursively by divide_and_conquer,\n",
    "#         see lecture slides for details)\n",
    "# Hint 6: The list of nodes output by divide_and_conquer may finally be converted to an array, where each nodeno in the \n",
    "#         tuples corresponds to an index of the array \n",
    "#\n",
    "# Input to predict:\n",
    "# self: the object itself\n",
    "# df: a dataframe\n",
    "# \n",
    "# Output from predict:\n",
    "# predictions: a dataframe with class labels as column names and the rows corresponding to\n",
    "#              predictions with estimated class probabilities for each row in df, where the class probabilities\n",
    "#              are the relative class frequencies in the leaves of the decision tree into which the instances in\n",
    "#              df fall\n",
    "#\n",
    "# Hint 1: Drop any \"CLASS\" and \"ID\" columns first and then apply imputation and binning\n",
    "# Hint 2: Iterate over the rows calling some sub-function, e.g., make_prediction(nodeno,row), which for a test row\n",
    "#         finds a leaf node from which class probabilities are obtained\n",
    "# Hint 3: This sub-function may recursively traverse the tree (represented by an array), starting with the nodeno\n",
    "#         that corresponds to the root\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (5, 'equal-width', 3): 1.58 s.\n",
      "Testing time (5, 'equal-width', 3): 0.11 s.\n",
      "Training time (5, 'equal-width', 5): 1.33 s.\n",
      "Testing time (5, 'equal-width', 5): 0.11 s.\n",
      "Training time (5, 'equal-width', 10): 0.74 s.\n",
      "Testing time (5, 'equal-width', 10): 0.11 s.\n",
      "Training time (5, 'equal-size', 3): 1.60 s.\n",
      "Testing time (5, 'equal-size', 3): 0.07 s.\n",
      "Training time (5, 'equal-size', 5): 0.84 s.\n",
      "Testing time (5, 'equal-size', 5): 0.07 s.\n",
      "Training time (5, 'equal-size', 10): 0.44 s.\n",
      "Testing time (5, 'equal-size', 10): 0.07 s.\n",
      "Training time (10, 'equal-width', 3): 2.47 s.\n",
      "Testing time (10, 'equal-width', 3): 0.06 s.\n",
      "Training time (10, 'equal-width', 5): 1.56 s.\n",
      "Testing time (10, 'equal-width', 5): 0.06 s.\n",
      "Training time (10, 'equal-width', 10): 0.88 s.\n",
      "Testing time (10, 'equal-width', 10): 0.06 s.\n",
      "Training time (10, 'equal-size', 3): 1.51 s.\n",
      "Testing time (10, 'equal-size', 3): 0.07 s.\n",
      "Training time (10, 'equal-size', 5): 1.32 s.\n",
      "Testing time (10, 'equal-size', 5): 0.07 s.\n",
      "Training time (10, 'equal-size', 10): 1.25 s.\n",
      "Testing time (10, 'equal-size', 10): 0.08 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-width</th>\n",
       "      <th>3</th>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.566861</td>\n",
       "      <td>0.794838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.530257</td>\n",
       "      <td>0.812039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.540913</td>\n",
       "      <td>0.802684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-size</th>\n",
       "      <th>3</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>0.757026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.644065</td>\n",
       "      <td>0.759834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.652672</td>\n",
       "      <td>0.743455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-width</th>\n",
       "      <th>3</th>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.566439</td>\n",
       "      <td>0.816216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.529316</td>\n",
       "      <td>0.832679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.503810</td>\n",
       "      <td>0.845034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">equal-size</th>\n",
       "      <th>3</th>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.905079</td>\n",
       "      <td>0.656123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.902743</td>\n",
       "      <td>0.655598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.532710</td>\n",
       "      <td>0.868821</td>\n",
       "      <td>0.669287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy  Brier score       AUC\n",
       "5  equal-width 3   0.635514     0.566861  0.794838\n",
       "               5   0.644860     0.530257  0.812039\n",
       "               10  0.579439     0.540913  0.802684\n",
       "   equal-size  3   0.644860     0.678333  0.757026\n",
       "               5   0.635514     0.644065  0.759834\n",
       "               10  0.598131     0.652672  0.743455\n",
       "10 equal-width 3   0.654206     0.566439  0.816216\n",
       "               5   0.626168     0.529316  0.832679\n",
       "               10  0.598131     0.503810  0.845034\n",
       "   equal-size  3   0.504673     0.905079  0.656123\n",
       "               5   0.504673     0.902743  0.655598\n",
       "               10  0.532710     0.868821  0.669287"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code (leave this part unchanged, except for if auc is undefined)\n",
    "\n",
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.txt\")\n",
    "\n",
    "tree_model = DecisionTree()\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "nobins_values = [5,10]\n",
    "bintype_values = [\"equal-width\",\"equal-size\"]\n",
    "min_samples_split_values = [3,5,10]\n",
    "parameters = [(nobins,bintype,min_samples_split) for nobins in nobins_values for bintype in bintype_values \n",
    "              for min_samples_split in min_samples_split_values]\n",
    "\n",
    "results = np.empty((len(parameters),3))\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    t0 = time.perf_counter()\n",
    "    tree_model.fit(glass_train_df,nobins=parameters[i][0],bintype=parameters[i][1],min_samples_split=parameters[i][2])\n",
    "    print(\"Training time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = tree_model.predict(glass_test_df)\n",
    "    print(\"Testing time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels),\n",
    "                  auc(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=pd.MultiIndex.from_product([nobins_values,bintype_values,min_samples_split_values]),\n",
    "                       columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
    "\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.97\n",
      "AUC on training set: 1.00\n",
      "Brier score on training set: 0.03\n"
     ]
    }
   ],
   "source": [
    "train_labels = glass_train_df[\"CLASS\"]\n",
    "tree_model.fit(glass_train_df,min_samples_split=1)\n",
    "predictions = tree_model.predict(glass_train_df)\n",
    "print(\"Accuracy on training set: {0:.2f}\".format(accuracy(predictions,train_labels)))\n",
    "print(\"AUC on training set: {0:.2f}\".format(auc(predictions,train_labels)))\n",
    "print(\"Brier score on training set: {0:.2f}\".format(brier_score(predictions,train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on assumptions, things that do not work properly, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the class DecisionForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionForest:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.binning = None\n",
    "        self.imputation = None\n",
    "        self.labels = None\n",
    "        # models is now a list of a list. So it is the list of trees, i.e. the list of the list of nodes\n",
    "        self.models = None\n",
    "        # nodenomax is the maximum nodeno which has been given to a tree so it is a reference to know what should\n",
    "        # be the nodeno of the next node\n",
    "        # nodenomax is now  list of the nodenomax of the trees\n",
    "        self.nodenomax = None\n",
    "        self.notrees = None\n",
    "        \n",
    "    ## This function takes a list of feature and a dataframe and gives the feature_to_select: the feature which minimises \n",
    "    ## the residual information and the list of sub_features which is the features minus the feature_to_select\n",
    "    def select_feature_min_inf(self,features, df):\n",
    "        # spec_agg is a special aggregation function\n",
    "        # the input df is a groupedby dataframe, which is a groupedby df by featureI (one feature selected) of a dataframe\n",
    "        # which is itself a size() dataframe by (featureI, class)\n",
    "        # This aim of this function is to give the residual information for one feature\n",
    "        # NB: We do not divide by the total cardinal as it would be the same for all features.\n",
    "        def spec_agg(df):\n",
    "            return(-np.sum(df*np.log(df/np.sum(df))))\n",
    "    \n",
    "        idx, minInf = 0, 1e5\n",
    "        for i in range(len(features)):\n",
    "            f = features[i]\n",
    "            # observed = True allows to remove the NA version of counts for categorical data, sort False for speed\n",
    "            class_repart = df.groupby([f, 'CLASS'], observed=True, sort = False).size()\n",
    "            # By aggregating with spec_agg we compute the inf residual in an efficient way\n",
    "            inf = class_repart.groupby([f]).agg(spec_agg).sum()\n",
    "            if(inf < minInf):\n",
    "                minInf = inf\n",
    "                idx = i\n",
    "        feature_to_select = features[idx]\n",
    "        if(idx==0):\n",
    "            sub_features = list(features[1:])\n",
    "        elif(idx==len(features)):\n",
    "            sub_features = list(features[:-1])\n",
    "        else:\n",
    "            sub_features = list(features[:idx]) + list(features[idx+1:])\n",
    "        return(feature_to_select, sub_features)\n",
    "    \n",
    "    def divide_and_conquer(self, df, features, class_freq, min_samples_split, nodeno, notree):\n",
    "        feature_to_select, sub_features = self.select_feature_min_inf(features,df)\n",
    "        #Generating the sub trees\n",
    "        values = df[feature_to_select].unique()\n",
    "        trees = []\n",
    "        sub_nodeno = self.nodenomax[notree]\n",
    "        nodedict = {}\n",
    "        # Made to improve the speed\n",
    "        df.set_index(feature_to_select, inplace=True)\n",
    "        for i in values:\n",
    "            sub_df = df.loc[[i]]\n",
    "            sub_class_freq = sub_df.CLASS.value_counts(normalize=True)\n",
    "            self.nodenomax[notree] += 1\n",
    "            nodedict[i] = self.nodenomax[notree]\n",
    "            # We are checking if we should create a new sub tree or if we should create a leaf\n",
    "            # leaf if we have less instances than min_sample or if we don't have anymore features\n",
    "            if((sub_df.shape[0]<=min_samples_split or len(sub_features)==0)):\n",
    "                sub_tree = ((self.nodenomax[notree], \"leaf\", sub_class_freq))\n",
    "            else:\n",
    "                sub_tree = self.divide_and_conquer(sub_df, sub_features, sub_class_freq, min_samples_split, self.nodenomax[notree], notree)\n",
    "                \n",
    "            self.models[notree].append(sub_tree)\n",
    "        this_tree = (nodeno, feature_to_select, nodedict)\n",
    "        return(this_tree)\n",
    "        \n",
    "    def fit(self, df, nobins = 10, bintype = 'equal-width', min_samples_split = 5, random_features = 2, notrees = 10):\n",
    "        self.__init__()\n",
    "        if(random_features==0):\n",
    "            random_features = df.shape[1]-2\n",
    "        self.notrees = notrees\n",
    "        df, self.imputation = create_imputation(df)\n",
    "        classColumn = df.loc[:,'CLASS'].astype('category')\n",
    "        self.labels = classColumn.cat.categories\n",
    "        df, self.binning = create_bins(df, nobins = nobins, bintype = bintype)\n",
    "        self.nodenomax = np.zeros(notrees, dtype='int')\n",
    "        self.models = [[] for i in range(notrees)]\n",
    "        n, m = df.shape[0], random_features\n",
    "        features = df.columns\n",
    "        features_index = [i for i in range(len(features)) if features[i] not in ['ID', 'CLASS']]\n",
    "        class_idx = list(np.where(features == 'CLASS')[0])\n",
    "        for i in range(notrees):\n",
    "            # We generate the random list of instances and features\n",
    "            idx, fts = np.random.choice(n, size=n, replace=True),np.random.choice(features_index, size=m, replace=False)\n",
    "            # We should not forget to include the CLASS column in addition to the features\n",
    "            sub_df = df.iloc[idx, list(fts)+(class_idx)]\n",
    "            class_freq = sub_df.CLASS.value_counts(normalize=True).sort_index()\n",
    "            sub_features = features[fts]\n",
    "            tree = self.divide_and_conquer(sub_df, sub_features, class_freq, min_samples_split, 0, i)\n",
    "            self.models[i].append(tree)\n",
    "            self.models[i] = sorted(self.models[i], key=lambda x:x[0])\n",
    "                \n",
    "                \n",
    "    ## This recursive funtion takes a row and a nodeno and will go through the nodes to find the probabilities\n",
    "    ## giving back a vector of size number of labels           \n",
    "    def make_prediction(self, nodeno, row, notree):\n",
    "        def closer_idx(value,keys):\n",
    "            idx = np.argmin(np.abs(np.array(list((keys)), dtype='int')-int(value)))\n",
    "            return(list(keys)[idx])\n",
    "        nodeno, f, d = self.models[notree][int(nodeno)]\n",
    "        if(f == \"leaf\"):\n",
    "            return(d.sort_index())\n",
    "        else:\n",
    "            value = row[f]\n",
    "            # We have some case where we don't have any node for the values of row\n",
    "            if(value not in d.keys()):\n",
    "                # if so we will go in the deepest node compatible and average the predictions of the sub_nodes\n",
    "                v = list(d.values())\n",
    "                m = np.zeros([len(v), len(self.labels)])\n",
    "                for i in range(len(v)):\n",
    "                     m[i] = self.make_prediction(v[i], row, notree)\n",
    "                m = np.mean(m, axis = 0)\n",
    "                return(m)\n",
    "            else:\n",
    "                # else we just iterate in the good next node\n",
    "                new_nodeno = d[value]\n",
    "            return(self.make_prediction(new_nodeno, row, notree))\n",
    "    \n",
    "        \n",
    "        \n",
    "    def predict(self, df):\n",
    "        df = df.drop(['ID', 'CLASS'], axis = 1)\n",
    "        df = apply_imputation(df_init=df, imputation=self.imputation)\n",
    "        df = apply_bins(df_init=df, binning=self.binning)\n",
    "        matrix = np.array([np.zeros(len(self.labels)) for i in range (df.shape[0])])\n",
    "        for i in range(df.shape[0]):\n",
    "            row = df.iloc[i]\n",
    "            mat_pred_i = np.zeros([self.notrees, len(self.labels)])\n",
    "            # We iterate the prediction over all trees and average the result\n",
    "            for j in range(self.notrees):\n",
    "                mat_pred_i[j] = self.make_prediction(0, row, j)\n",
    "            mat_pred_avg = np.mean(mat_pred_i, axis = 0)\n",
    "            matrix[i] = mat_pred_avg\n",
    "        # We need to add the predictions of the labels that might not have been present in the training set\n",
    "        # for example label 4 is never represented so it should appear wth a prob of 0 for all rows\n",
    "        probs = pd.DataFrame(matrix, columns=self.labels)\n",
    "        max_i = np.max(a=np.array(probs.columns, dtype='int'))\n",
    "        for i in range(1,max_i):\n",
    "            if (i not in probs.columns):\n",
    "                probs[i] = 0\n",
    "        cols = sorted(predictions.columns)\n",
    "        probs = probs.loc[:,cols]\n",
    "        return(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (1, 1): 0.48 s.\n",
      "Testing time (1, 1): 0.49 s.\n",
      "Training time (1, 2): 2.59 s.\n",
      "Testing time (1, 2): 0.71 s.\n",
      "Training time (1, 5): 18.16 s.\n",
      "Testing time (1, 5): 1.05 s.\n",
      "Training time (2, 1): 0.72 s.\n",
      "Testing time (2, 1): 0.51 s.\n",
      "Training time (2, 2): 2.20 s.\n",
      "Testing time (2, 2): 0.92 s.\n",
      "Training time (2, 5): 18.90 s.\n",
      "Testing time (2, 5): 1.00 s.\n",
      "Training time (5, 1): 0.81 s.\n",
      "Testing time (5, 1): 0.86 s.\n",
      "Training time (5, 2): 2.33 s.\n",
      "Testing time (5, 2): 0.80 s.\n",
      "Training time (5, 5): 8.71 s.\n",
      "Testing time (5, 5): 0.82 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.631169</td>\n",
       "      <td>0.746790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.559199</td>\n",
       "      <td>0.771412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.455764</td>\n",
       "      <td>0.869111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.582253</td>\n",
       "      <td>0.816432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.508361</td>\n",
       "      <td>0.860150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.453809</td>\n",
       "      <td>0.864737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>1</th>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.590970</td>\n",
       "      <td>0.799225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.529303</td>\n",
       "      <td>0.852432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.453548</td>\n",
       "      <td>0.882252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Brier score       AUC\n",
       "1 1  0.579439     0.631169  0.746790\n",
       "  2  0.626168     0.559199  0.771412\n",
       "  5  0.616822     0.455764  0.869111\n",
       "2 1  0.663551     0.582253  0.816432\n",
       "  2  0.626168     0.508361  0.860150\n",
       "  5  0.616822     0.453809  0.864737\n",
       "5 1  0.654206     0.590970  0.799225\n",
       "  2  0.682243     0.529303  0.852432\n",
       "  5  0.663551     0.453548  0.882252"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.txt\")\n",
    "\n",
    "forest_model = DecisionForest()\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "min_samples_split_values = [1,2,5]\n",
    "random_features_values = [1,2,5]\n",
    "\n",
    "parameters = [(min_samples_split,random_features) for min_samples_split in min_samples_split_values \n",
    "              for random_features in random_features_values]\n",
    "\n",
    "results = np.empty((len(parameters),3))\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    t0 = time.perf_counter()\n",
    "    forest_model.fit(glass_train_df,min_samples_split=parameters[i][0],random_features=parameters[i][1])\n",
    "    print(\"Training time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = forest_model.predict(glass_test_df)\n",
    "    print(\"Testing time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels),\n",
    "                  auc(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=pd.MultiIndex.from_product([min_samples_split_values,random_features_values]),\n",
    "                       columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.85\n",
      "AUC on training set: 0.96\n",
      "Brier score on training set: 0.35\n"
     ]
    }
   ],
   "source": [
    "forest_model = DecisionForest()\n",
    "train_labels = glass_train_df[\"CLASS\"]\n",
    "forest_model.fit(glass_train_df,min_samples_split=1)\n",
    "predictions = forest_model.predict(glass_train_df)\n",
    "print(\"Accuracy on training set: {0:.2f}\".format(accuracy(predictions,train_labels)))\n",
    "print(\"AUC on training set: {0:.2f}\".format(auc(predictions,train_labels)))\n",
    "print(\"Brier score on training set: {0:.2f}\".format(brier_score(predictions,train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (1, 1): 7.51 s.\n",
      "Testing time (1, 1): 0.09 s.\n",
      "Training time (1, 2): 10.65 s.\n",
      "Testing time (1, 2): 0.09 s.\n",
      "Training time (1, 5): 19.78 s.\n",
      "Testing time (1, 5): 0.09 s.\n",
      "Training time (2, 1): 7.97 s.\n",
      "Testing time (2, 1): 0.09 s.\n",
      "Training time (2, 2): 12.01 s.\n",
      "Testing time (2, 2): 0.10 s.\n",
      "Training time (2, 5): 19.42 s.\n",
      "Testing time (2, 5): 0.10 s.\n",
      "Training time (5, 1): 4.57 s.\n",
      "Testing time (5, 1): 0.10 s.\n",
      "Training time (5, 2): 7.31 s.\n",
      "Testing time (5, 2): 0.09 s.\n",
      "Training time (5, 5): 9.75 s.\n",
      "Testing time (5, 5): 0.09 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.477912</td>\n",
       "      <td>0.860736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.411981</td>\n",
       "      <td>0.892842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.421511</td>\n",
       "      <td>0.895716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.452421</td>\n",
       "      <td>0.872447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.626168</td>\n",
       "      <td>0.411684</td>\n",
       "      <td>0.911137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.881621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>1</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.457859</td>\n",
       "      <td>0.865636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.410616</td>\n",
       "      <td>0.903016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.455782</td>\n",
       "      <td>0.883897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Brier score       AUC\n",
       "1 1  0.644860     0.477912  0.860736\n",
       "  2  0.710280     0.411981  0.892842\n",
       "  5  0.710280     0.421511  0.895716\n",
       "2 1  0.663551     0.452421  0.872447\n",
       "  2  0.626168     0.411684  0.911137\n",
       "  5  0.654206     0.435847  0.881621\n",
       "5 1  0.644860     0.457859  0.865636\n",
       "  2  0.719626     0.410616  0.903016\n",
       "  5  0.616822     0.455782  0.883897"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.txt\")\n",
    "\n",
    "forest_model = DecisionForest()\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "min_samples_split_values = [1,2,5]\n",
    "random_features_values = [1,2,5]\n",
    "\n",
    "parameters = [(min_samples_split,random_features) for min_samples_split in min_samples_split_values \n",
    "              for random_features in random_features_values]\n",
    "\n",
    "results = np.empty((len(parameters),3))\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    t0 = time.perf_counter()\n",
    "    forest_model.fit(glass_train_df,min_samples_split=parameters[i][0],random_features=parameters[i][1])\n",
    "    print(\"Training time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = forest_model.predict(glass_test_df)\n",
    "    print(\"Testing time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels),\n",
    "                  auc(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=pd.MultiIndex.from_product([min_samples_split_values,random_features_values]),\n",
    "                       columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.96\n",
      "AUC on training set: 1.00\n",
      "Brier score on training set: 0.12\n"
     ]
    }
   ],
   "source": [
    "train_labels = glass_train_df[\"CLASS\"]\n",
    "forest_model.fit(glass_train_df,min_samples_split=1)\n",
    "predictions = forest_model.predict(glass_train_df)\n",
    "print(\"Accuracy on training set: {0:.2f}\".format(accuracy(predictions,train_labels)))\n",
    "print(\"AUC on training set: {0:.2f}\".format(auc(predictions,train_labels)))\n",
    "print(\"Brier score on training set: {0:.2f}\".format(brier_score(predictions,train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on assumptions, things that do not work properly, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
